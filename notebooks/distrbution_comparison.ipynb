{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add validation tag to explanations based on scores\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "score_file = \"../scores.json\" \n",
    "data_file = \"../llama_3.1_explanation_raw.jsonl\"  \n",
    "output_file = \"../lama-8b_explanation_with_validation.jsonl\"\n",
    "\n",
    "with open(score_file, \"r\") as f:\n",
    "    score_data = json.load(f)\n",
    "score_data = {k: float(v) for k, v in score_data.items()}\n",
    "\n",
    "with open(data_file, \"r\") as f:\n",
    "    all_data = [json.loads(line) for line in f]\n",
    "\n",
    "for instance in tqdm(all_data):\n",
    "    inst_id = instance[\"id\"]\n",
    "    new_comments = []\n",
    "    for idx, (reason_text, label_code) in enumerate(instance[\"generated_explanations\"]):\n",
    "        reason_id = f\"{inst_id}_{label_code}-{idx}\"\n",
    "        if reason_id in score_data and score_data[reason_id] > 0.5:\n",
    "            tag = \"validated\"\n",
    "        elif reason_id in score_data and score_data[reason_id] <= 0.5:\n",
    "            tag = \"not_validated\"\n",
    "        else:\n",
    "            print(\"missing:\", reason_id)\n",
    "\n",
    "        new_comments.append([reason_text, label_code, tag])\n",
    "    instance[\"generated_explanations\"] = new_comments\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for instance in all_data:\n",
    "        f.write(json.dumps(instance, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label-level counts\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_file = \"../lama-8b_explanation_with_validation.jsonl\"\n",
    "output_file = \"../lama-8b_explanation_with_validation_count.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    all_data = [json.loads(line) for line in f]\n",
    "\n",
    "for instance in tqdm(all_data):\n",
    "    comments = instance.get(\"generated_explanations\", [])\n",
    "\n",
    "    count_r1 = defaultdict(int)\n",
    "    count_r2 = defaultdict(int)\n",
    "\n",
    "    for reason_text, label_code, tag in comments:\n",
    "        count_r1[label_code] += 1  \n",
    "        if tag == \"validated\":\n",
    "            count_r2[label_code] += 1 \n",
    "\n",
    "    set_r1 = set(count_r1.keys())\n",
    "    set_r2 = set(count_r2.keys())\n",
    "\n",
    "    instance[\"label_count_round_1\"] = dict(count_r1)\n",
    "    instance[\"label_set_round_1\"] = list(set_r1)\n",
    "\n",
    "    instance[\"label_count_round_2\"] = dict(count_r2)\n",
    "    instance[\"label_set_round_2\"] = list(set_r2)\n",
    "\n",
    " \n",
    "    instance[\"error\"] = list(set_r1 - set_r2)\n",
    "    not_validated_exp = {\n",
    "        label: count_r1[label] - count_r2.get(label, 0)\n",
    "        for label in count_r1\n",
    "        if count_r1[label] - count_r2.get(label, 0) > 0\n",
    "    }\n",
    "    instance[\"not_validated_exp\"] = not_validated_exp\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for instance in all_data:\n",
    "        f.write(json.dumps(instance, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c27e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error comparison between LLM validation and VariErr dataset\n",
    "\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_a_path = \"../lama-8b_explanation_with_validation_count.jsonl\"\n",
    "file_b_path = \"../varierr.json\"\n",
    "output_csv_path = \"../merged_errors.csv\"\n",
    "\n",
    "with open(file_a_path, \"r\") as f:\n",
    "    data_a = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "with open(file_b_path, \"r\") as f:\n",
    "    data_b = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "all_ids = list(data_a.keys())\n",
    "\n",
    "with open(output_csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"id\", \"llm_not_calidated_error\", \"varierr_error\"])\n",
    "    writer.writeheader()\n",
    "\n",
    "    for id_ in tqdm(all_ids):\n",
    "        if id_ not in data_b:\n",
    "            print(f\"ID {id_} not found in VariErr dataset.\")\n",
    "        \n",
    "        row = {\n",
    "            \"id\": id_,\n",
    "            \"llm_not_calidated_error\": json.dumps(data_a.get(id_, {}).get(\"error\", []), ensure_ascii=False),\n",
    "            \"varierr_error\": json.dumps(data_b.get(id_, {}).get(\"error_labels\", []), ensure_ascii=False)\n",
    "        }\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV saved to：{output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f236be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSD between model and human distributions_chaosnli\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from pathlib import Path\n",
    "\n",
    "# label_map = {\"e\": \"entailment\", \"n\": \"neutral\", \"c\": \"contradiction\"}\n",
    "label_order = [\"e\", \"n\", \"c\"]\n",
    "\n",
    "\n",
    "def normalize(counts):\n",
    "    arr = np.array(counts, dtype=np.float64)\n",
    "    if arr.sum() == 0:\n",
    "        return np.ones_like(arr) / len(arr)\n",
    "    return arr / arr.sum()\n",
    "\n",
    "\n",
    "def load_model_counts(file_path):\n",
    "    dist_map = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            uid = data[\"id\"]\n",
    "            label_counts = data.get(\"label_count_round_1\", {})  # change here 1 or 2\n",
    "\n",
    "            dist_map[uid] = {\n",
    "                \"e\": float(label_counts.get(\"e\", 0) or 0),\n",
    "                \"n\": float(label_counts.get(\"n\", 0) or 0),\n",
    "                \"c\": float(label_counts.get(\"c\", 0) or 0)\n",
    "            }\n",
    "\n",
    "    return dist_map\n",
    "\n",
    "def load_human_counts(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        records = [json.loads(line) for line in f]\n",
    "\n",
    "    dist_map = {}\n",
    "    for r in records:\n",
    "        uid = r[\"uid\"]\n",
    "        counter = r[\"label_counter\"]\n",
    "        dist_map[uid] = {k: v for k, v in counter.items()}\n",
    "    \n",
    "    # print(dist_map)\n",
    "    return dist_map\n",
    "\n",
    "def kl_divergence(p, q, eps=1e-12):\n",
    "    p = np.array(p, dtype=np.float64) + eps\n",
    "    q = np.array(q, dtype=np.float64) + eps\n",
    "    return np.sum(p * np.log2(p / q))\n",
    "\n",
    "\n",
    "def compare_distributions(model_counts, human_counts):\n",
    "    rows = []\n",
    "    shared_ids = set(model_counts.keys()) & set(human_counts.keys())\n",
    "    # print(shared_ids)\n",
    "\n",
    "    for uid in shared_ids:\n",
    "        model_vec = [model_counts[uid].get(label, 0) for label in label_order]\n",
    "        human_vec = [human_counts[uid].get(label, 0) for label in label_order]\n",
    "        # print(f\"uid: {uid}, model_vec: {model_vec}, human_vec: {human_vec}\")\n",
    "\n",
    "        model_dist = normalize(model_vec)\n",
    "        human_dist = normalize(human_vec)\n",
    "      \n",
    "        jsd = jensenshannon(model_dist, human_dist, base=2.0) ** 2\n",
    "        kl = kl_divergence(model_dist, human_dist)\n",
    "\n",
    "        rows.append({\n",
    "            \"uid\": uid,\n",
    "            \"js_divergence\": jsd,\n",
    "            \"kl_divergence\": kl,\n",
    "            \"model_distribution\": model_dist.tolist(),\n",
    "            \"human_distribution\": human_dist.tolist(),\n",
    "            \"model_counts\": model_vec,\n",
    "            \"human_counts\": human_vec,\n",
    "        })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def main(model_file, human_file, output_csv):\n",
    "    model_counts = load_model_counts(model_file)\n",
    "    human_counts = load_human_counts(human_file)\n",
    "\n",
    "    comparison = compare_distributions(model_counts, human_counts)\n",
    "    df = pd.DataFrame(comparison)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_file = \"../lama-8b_explanation_with_validation_count.jsonl\"    \n",
    "    human_file = \"../chaosNLI_mnli_m.jsonl\"    \n",
    "    output_file = \"../chaos_llama_8b_jsd_kl_before.csv\"\n",
    "    main(model_file, human_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801684ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSD between model and human distributions_varierr\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from pathlib import Path\n",
    "\n",
    "# label_map = {\"e\": \"entailment\", \"n\": \"neutral\", \"c\": \"contradiction\"}\n",
    "label_order = [\"e\", \"n\", \"c\"]\n",
    "\n",
    "\n",
    "def normalize(counts):\n",
    "    arr = np.array(counts, dtype=np.float64)\n",
    "    if arr.sum() == 0:\n",
    "        return np.ones_like(arr) / len(arr)\n",
    "    return arr / arr.sum()\n",
    "\n",
    "\n",
    "def load_model_counts(file_path):\n",
    "    dist_map = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            uid = data[\"id\"]\n",
    "            label_counts = data.get(\"label_count_round_1\", {})  # change here 1 or 2\n",
    "\n",
    "            dist_map[uid] = {\n",
    "                \"e\": float(label_counts.get(\"e\", 0) or 0),\n",
    "                \"n\": float(label_counts.get(\"n\", 0) or 0),\n",
    "                \"c\": float(label_counts.get(\"c\", 0) or 0)\n",
    "            }\n",
    "\n",
    "    return dist_map\n",
    "\n",
    "\n",
    "def load_human_counts(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        records = [json.loads(line) for line in f]  \n",
    "\n",
    "    dist_map = {}\n",
    "    for r in records:\n",
    "        uid = r[\"id\"]\n",
    "        raw_counts = r.get(\"label_count_round_1\", {})   # change here 1 or 2\n",
    "\n",
    "        counter = {\n",
    "            \"e\": float(raw_counts.get(\"entailment\") or 0),\n",
    "            \"n\": float(raw_counts.get(\"neutral\") or 0),\n",
    "            \"c\": float(raw_counts.get(\"contradiction\") or 0)\n",
    "        }\n",
    "\n",
    "        dist_map[uid] = counter\n",
    "\n",
    "    print(dist_map)\n",
    "    return dist_map\n",
    "\n",
    "def kl_divergence(p, q, eps=1e-12):\n",
    "    p = np.array(p, dtype=np.float64) + eps\n",
    "    q = np.array(q, dtype=np.float64) + eps\n",
    "    return np.sum(p * np.log2(p / q))\n",
    "\n",
    "\n",
    "def compare_distributions(model_counts, human_counts):\n",
    "    rows = []\n",
    "    shared_ids = set(model_counts.keys()) & set(human_counts.keys())\n",
    "    print(f\"number of shared IDs:\",len(shared_ids))\n",
    "\n",
    "    for uid in shared_ids:\n",
    "        model_vec = [model_counts[uid].get(label, 0) for label in label_order]\n",
    "        human_vec = [human_counts[uid].get(label, 0) for label in label_order]\n",
    "        # print(f\"uid: {uid}, model_vec: {model_vec}, human_vec: {human_vec}\")\n",
    "\n",
    "        model_dist = normalize(model_vec)\n",
    "        human_dist = normalize(human_vec)\n",
    "\n",
    "        jsd = jensenshannon(model_dist, human_dist, base=2.0) ** 2\n",
    "        kl = kl_divergence(model_dist, human_dist)\n",
    "\n",
    "        rows.append({\n",
    "            \"uid\": uid,\n",
    "            \"js_divergence\": jsd,\n",
    "            \"kl_divergence\": kl,\n",
    "            \"model_distribution\": model_dist.tolist(),\n",
    "            \"human_distribution\": human_dist.tolist(),\n",
    "            \"model_counts\": model_vec,\n",
    "            \"human_counts\": human_vec,\n",
    "        })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def main(model_file, human_file, output_csv):\n",
    "    model_counts = load_model_counts(model_file)\n",
    "    human_counts = load_human_counts(human_file)\n",
    "\n",
    "    comparison = compare_distributions(model_counts, human_counts)\n",
    "    df = pd.DataFrame(comparison)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(\"Saved.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_file = \"../lama-8b_explanation_with_validation_count.jsonl\" \n",
    "    human_file = \"../varierr.json\"   \n",
    "    output_file = \"../varierr_llama_8b_jsd_kl_before.csv\"\n",
    "    main(model_file, human_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d688da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average score\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"../dist_eval/chaos_llama_8b_jsd_kl_before.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "mean_jsd = df[\"js_divergence\"].mean()\n",
    "mean_kld = df[\"kl_divergence\"].mean()\n",
    "\n",
    "print(f\"Average JSD：{mean_jsd:.4f}\")\n",
    "print(f\"Average KLD：{mean_kld:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
