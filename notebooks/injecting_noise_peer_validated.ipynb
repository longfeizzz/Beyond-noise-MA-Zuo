{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到peer-validated的pair,写入label_count_round_3\n",
    "\n",
    "import json\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\"\n",
    "labels = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        peer_validated_count = {}\n",
    "\n",
    "        for label in labels:\n",
    "            explanations = data.get(label, [])\n",
    "            count = 0\n",
    "\n",
    "            for entry in explanations:\n",
    "                if not isinstance(entry, dict):\n",
    "                    continue\n",
    "                ak = entry.get(\"annotator\")\n",
    "                peer_yes_votes = 0\n",
    "\n",
    "                for j in entry.get(\"judgments\", []):\n",
    "                    if not isinstance(j, dict):\n",
    "                        continue\n",
    "                    if j.get(\"annotator\") != ak and j.get(\"makes_sense\") is True:\n",
    "                        peer_yes_votes += 1\n",
    "\n",
    "                if peer_yes_votes >= 2:\n",
    "                    count += 1\n",
    "\n",
    "            peer_validated_count[label] = count if count > 0 else None\n",
    "\n",
    "        data[\"label_count_round_3\"] = peer_validated_count\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 新文件已生成，每条数据均包含完整的 peer_validated 字段（三类标签，值为整数或 null）。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated --> label_set_round_3\n",
    "\n",
    "import json\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer.json\"\n",
    "labels = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        label_count_round_3 = data.get(\"label_count_round_3\", {})\n",
    "\n",
    "        label_set_round_3 = []\n",
    "        for label in labels:\n",
    "            count = label_count_round_3.get(label)\n",
    "            if count is not None and count >= 1:\n",
    "                label_set_round_3.append(label)\n",
    "\n",
    "        # 新增到数据里\n",
    "        data[\"label_set_round_3\"] = label_set_round_3\n",
    "\n",
    "        # 保存\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 新文件已生成，每条数据都包含了 label_set_round_3。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 全部正确！现在开始写入新的文件...\n",
      "✅ 已生成新文件，路径为：/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\n"
     ]
    }
   ],
   "source": [
    "## label_set_round_1 - label_set_round_3 = error_peer\n",
    "import json\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\"\n",
    "\n",
    "all_passed = True\n",
    "error_records = []  # 用来收集不符合要求的 id\n",
    "\n",
    "# 先整体检查\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        label_set_round_1 = set(data.get(\"label_set_round_1\", []))\n",
    "        label_set_round_2 = set(data.get(\"label_set_round_2\", []))\n",
    "        error_labels = set(data.get(\"error_labels\", []))\n",
    "\n",
    "        if label_set_round_1 - label_set_round_2 != error_labels:\n",
    "            all_passed = False\n",
    "            error_records.append(data.get(\"id\", \"unknown_id\"))\n",
    "\n",
    "# 检查结果\n",
    "if all_passed:\n",
    "    print(\"✅ 全部正确！现在开始写入新的文件...\")\n",
    "\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            label_set_round_1 = set(data.get(\"label_set_round_1\", []))\n",
    "            label_set_round_3 = set(data.get(\"label_set_round_3\", []))\n",
    "\n",
    "            error_peer = list(label_set_round_1 - label_set_round_3)\n",
    "            data[\"error_peer\"] = error_peer\n",
    "\n",
    "            outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ 已生成新文件，路径为：{output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 有不符合的记录！以下是出错的样本 ID：\")\n",
    "    for eid in error_records:\n",
    "        print(eid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected noise into /Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_44.json\n"
     ]
    }
   ],
   "source": [
    "## random noise\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "def inject_multiple_noises(input_path, output_path, seed, label_choices=[\"entailment\", \"neutral\", \"contradiction\"]):\n",
    "    random.seed(seed) \n",
    "    with open(input_path, 'r', encoding='utf-8') as fin, open(output_path, 'w', encoding='utf-8') as fout:\n",
    "        for line in fin:\n",
    "            data = json.loads(line.strip())\n",
    "            error_labels = data.get(\"error_peer\", [])\n",
    "\n",
    "            if error_labels:\n",
    "                noise_labels = [random.choice(label_choices) for _ in error_labels]\n",
    "                data[\"random_noise_peer\"] = noise_labels\n",
    "\n",
    "            fout.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "    print(f\"Injected noise into {output_path}\")\n",
    "\n",
    "inject_multiple_noises(\"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\", \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_44.json\", seed=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成： /Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_count_44.json\n"
     ]
    }
   ],
   "source": [
    "# new count \n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_44.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_count_44.json\"\n",
    "\n",
    "\n",
    "labels = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        label_set_round_3 = set(data.get(\"label_set_round_3\", []))\n",
    "        noise_peer = data.get(\"random_noise_peer\", [])\n",
    "\n",
    "        # 统计 error_peer 中每个标签出现次数\n",
    "        noise_counter = Counter(noise_peer)\n",
    "\n",
    "        # 构建 random_noise_labels_count\n",
    "        random_noise_labels_count = {}\n",
    "        for label in labels:\n",
    "            count = 0\n",
    "\n",
    "            # 如果 label 在 label_set_round_3 出现过，加1\n",
    "            if label in label_set_round_3:\n",
    "                count += 1\n",
    "\n",
    "            count += noise_counter.get(label, 0)\n",
    "\n",
    "            # 如果最终 count 是0，就设为 null，否则 float(count)\n",
    "            random_noise_labels_count[label] = float(count) if count > 0 else None\n",
    "\n",
    "        # 只新增 random_noise_labels_count，不动 label_set_round_3\n",
    "        data[\"random_noise_labels_count\"] = random_noise_labels_count\n",
    "\n",
    "        # 保存新的数据\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 完成：\", output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"id\": \"10229n\", \"context\": \"The governing statute provides that a committee consisting of the Comptroller General, the Speaker of the House and President Pro Tempore of the Senate, the Majority and Minority leaders, and the Chairmen and Ranking Minority Members of the Senate Governmental Affairs and House Government Reform Committees recommend an individual to the President for appointment.\", \"statement\": \"The process is long and will be reformed in the coming years.\", \"entailment\": [], \"neutral\": [{\"annotator\": 0, \"id\": \"531-neutral-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The context makes no mention about how long the process takes and whether it will be reformed.\", \"self_corrected\": false}, {\"annotator\": 1, \"id\": \"531-neutral-2\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"While the context could suggest that the process takes long because so many individuals are involved, it does not say anything about reform.\", \"self_corrected\": false}, {\"annotator\": 2, \"id\": \"531-neutral-3\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"\\\"Reform\\\" is not mentioned in the context.\", \"self_corrected\": false}, {\"annotator\": 3, \"id\": \"531-neutral-4\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The time duration of the process is not mentioned\", \"self_corrected\": false}], \"contradiction\": [], \"idk\": [], \"label_count_round_1\": {\"contradiction\": null, \"entailment\": null, \"neutral\": 4.0}, \"label_count_round_2\": {\"contradiction\": null, \"entailment\": null, \"neutral\": 4.0}, \"label_set_round_1\": [\"neutral\"], \"label_set_round_2\": [\"neutral\"], \"error_labels\": [], \"has_ambiguity\": false, \"chaosnli_labels\": {\"c\": 18, \"n\": 79, \"e\": 3}, \"labels\": [0.0, 1.0, 0.0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m label_counts = item.get(\u001b[33m\"\u001b[39m\u001b[33mlabel_set_round_1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_counts:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     item[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mconvert_label_count_to_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m json.dump(item, outfile)\n\u001b[32m     32\u001b[39m outfile.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mconvert_label_count_to_dist\u001b[39m\u001b[34m(label_count_dict)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_label_count_to_dist\u001b[39m(label_count_dict):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     c = \u001b[43mlabel_count_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mcontradiction\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m     e = label_count_dict.get(\u001b[33m\"\u001b[39m\u001b[33mentailment\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     13\u001b[39m     n = label_count_dict.get(\u001b[33m\"\u001b[39m\u001b[33mneutral\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "## 生成distribution\n",
    "\n",
    "import json\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/2_llm_validation/500/LLM_exp+LLM_dist+LLM_validate/llama_70b/llama33_70b_explanation_with_validation_count.jsonl\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/2_llm_validation/500/LLM_exp+LLM_dist+LLM_validate/llama_70b/llama33_70b_explanation_with_validation_dist.jsonl\"\n",
    "\n",
    "\n",
    "def convert_label_count_to_dist(label_count_dict):\n",
    "\n",
    "    c = label_count_dict.get(\"contradiction\") or 0\n",
    "    e = label_count_dict.get(\"entailment\") or 0\n",
    "    n = label_count_dict.get(\"neutral\") or 0\n",
    "\n",
    "    total = c + e + n\n",
    "    if total == 0:\n",
    "        return [0.0, 0.0, 0.0]  # 避免除0\n",
    "    return [e / total, n / total, c / total]  # 顺序为 [e, n, c]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "\n",
    "        ## change here \"random_noise_labels_count\"/\"distribution_noise_label_count\"\n",
    "        label_counts = item.get(\"label_set_round_2\")\n",
    "        if label_counts:\n",
    "            item[\"label\"] = convert_label_count_to_dist(label_counts)\n",
    "\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"处理完成，已写入新文件：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_dist_44.json: 500it [00:00, 8749.40it/s]\n"
     ]
    }
   ],
   "source": [
    "## clean\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_label_dist(chaos_dict):\n",
    "    # 标签顺序固定：[\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    label_order = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    values = [(chaos_dict.get(k) or 0.0) for k in label_order]  # 将 None 转换为 0.0\n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return [0.0] * 3\n",
    "    return [v / total for v in values]\n",
    "\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in tqdm(fin, desc=f\"Processing {input_path}\"):\n",
    "            raw = json.loads(line)\n",
    "            out = {\n",
    "                \"uid\": raw.get(\"id\", raw.get(\"uid\")),\n",
    "                \"premise\": raw.get(\"context\") or raw[\"example\"][\"premise\"],\n",
    "                \"hypothesis\": raw.get(\"statement\") or raw[\"example\"][\"hypothesis\"],\n",
    "                \"label\": raw.get(\"label\")\n",
    "            }\n",
    "            fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 示例调用方式\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_dist_44.json\"\n",
    "    output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_random_noise/varierr_peer_random_cleaned_44.json\"\n",
    "    process_file(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distributional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## distributional\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "def inject_noise_with_distribution(input_file, output_file, seed):\n",
    "    label_pool = ['entailment', 'neutral', 'contradiction']\n",
    "    label_weights = [87, 69, 82]\n",
    "    random.seed(seed)\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as fin, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as fout:\n",
    "        \n",
    "        for line in fin:\n",
    "            data = json.loads(line.strip())\n",
    "\n",
    "            error_count = len(data.get(\"error_peer\", []))\n",
    "            if error_count > 0:\n",
    "                noise_labels = random.choices(label_pool, weights=label_weights, k=error_count)\n",
    "                data[\"distribution_noise_label\"] = noise_labels \n",
    "            fout.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "inject_noise_with_distribution(\"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\", \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_44.json\", seed=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成： /Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_count_44.json\n"
     ]
    }
   ],
   "source": [
    "# new count \n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_44.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_count_44.json\"\n",
    "\n",
    "\n",
    "labels = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        label_set_round_3 = set(data.get(\"label_set_round_3\", []))\n",
    "        noise_peer = data.get(\"distribution_noise_label\", [])\n",
    "\n",
    "        # 统计 error_peer 中每个标签出现次数\n",
    "        noise_counter = Counter(noise_peer)\n",
    "\n",
    "        # 构建 random_noise_labels_count\n",
    "        dist_noise_labels_count = {}\n",
    "        for label in labels:\n",
    "            count = 0\n",
    "\n",
    "            # 如果 label 在 label_set_round_3 出现过，加1\n",
    "            if label in label_set_round_3:\n",
    "                count += 1\n",
    "\n",
    "            # 再加上在 error_peer 里出现的次数\n",
    "            count += noise_counter.get(label, 0)\n",
    "\n",
    "            # 如果最终 count 是0，就设为 null，否则 float(count)\n",
    "            dist_noise_labels_count[label] = float(count) if count > 0 else None\n",
    "\n",
    "        # 只新增 random_noise_labels_count，不动 label_set_round_3\n",
    "        data[\"dist_noise_labels_count\"] = dist_noise_labels_count\n",
    "\n",
    "        # 保存新的数据\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 完成：\", output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，已写入新文件：/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_dist_44.json\n"
     ]
    }
   ],
   "source": [
    "## 生成distribution\n",
    "\n",
    "import json\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_count_44.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_dist_44.json\"\n",
    "\n",
    "\n",
    "def convert_label_count_to_dist(label_count_dict):\n",
    "\n",
    "    c = label_count_dict.get(\"contradiction\") or 0\n",
    "    e = label_count_dict.get(\"entailment\") or 0\n",
    "    n = label_count_dict.get(\"neutral\") or 0\n",
    "\n",
    "    total = c + e + n\n",
    "    if total == 0:\n",
    "        return [0.0, 0.0, 0.0]  # 避免除0\n",
    "    return [e / total, n / total, c / total]  # 顺序为 [e, n, c]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "\n",
    "        ## change here \"random_noise_labels_count\"/\"dist_noise_labels_count\"\n",
    "        label_counts = item.get(\"dist_noise_labels_count\")\n",
    "        if label_counts:\n",
    "            item[\"label\"] = convert_label_count_to_dist(label_counts)\n",
    "\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"处理完成，已写入新文件：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_dist_44.json: 500it [00:00, 31114.09it/s]\n"
     ]
    }
   ],
   "source": [
    "## clean\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_label_dist(chaos_dict):\n",
    "    # 标签顺序固定：[\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    label_order = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    values = [(chaos_dict.get(k) or 0.0) for k in label_order]  # 将 None 转换为 0.0\n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return [0.0] * 3\n",
    "    return [v / total for v in values]\n",
    "\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in tqdm(fin, desc=f\"Processing {input_path}\"):\n",
    "            raw = json.loads(line)\n",
    "            out = {\n",
    "                \"uid\": raw.get(\"id\", raw.get(\"uid\")),\n",
    "                \"premise\": raw.get(\"context\") or raw[\"example\"][\"premise\"],\n",
    "                \"hypothesis\": raw.get(\"statement\") or raw[\"example\"][\"hypothesis\"],\n",
    "                \"label\": raw.get(\"label\")\n",
    "            }\n",
    "            fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 示例调用方式\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_dist_44.json\"\n",
    "    output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_peer_dist_noise/varierr_peer_dist_cleaned_44.json\"\n",
    "    process_file(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## peer-validated without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成！每行已新增 labels 分布，保存到： /Users/phoebeeeee/ongoing/Beyond-noise/dataset/repeated/varierr_original/varierr_peer_no_error_dist.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "input_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/varierr_with_peer_validated.json\"\n",
    "output_path = \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/repeated/no_error/varierr_peer_no_error_dist.json\"\n",
    "\n",
    "labels_order = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        label_count_round = data.get(\"label_count_round_3\", [])\n",
    "  \n",
    "        cleaned_counts = {label: (0.0 if label_count_round.get(label) is None else label_count_round.get(label))\n",
    "                          for label in labels_order}\n",
    "\n",
    "        total = sum(cleaned_counts.values())\n",
    "\n",
    "        if total == 0:\n",
    "            # 防止0除错误，如果没有任何label\n",
    "            label_distribution = [0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            label_distribution = [cleaned_counts[label] / total for label in labels_order]\n",
    "\n",
    "        # 加入新的labels字段\n",
    "        data[\"labels\"] = label_distribution\n",
    "\n",
    "        # 保存\n",
    "        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ 完成！每行已新增 labels 分布，保存到：\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /Users/phoebeeeee/ongoing/Beyond-noise/dataset/repeated/no_error/varierr_peer_no_error_dist.json: 500it [00:00, 27545.18it/s]\n"
     ]
    }
   ],
   "source": [
    "## clean no error\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_label_dist(chaos_dict):\n",
    "    # 标签顺序固定：[\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    label_order = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    values = [(chaos_dict.get(k) or 0.0) for k in label_order]  # 将 None 转换为 0.0\n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return [0.0] * 3\n",
    "    return [v / total for v in values]\n",
    "\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in tqdm(fin, desc=f\"Processing {input_path}\"):\n",
    "            raw = json.loads(line)\n",
    "            out = {\n",
    "                \"uid\": raw.get(\"id\", raw.get(\"uid\")),\n",
    "                \"premise\": raw.get(\"context\") or raw[\"example\"][\"premise\"],\n",
    "                \"hypothesis\": raw.get(\"statement\") or raw[\"example\"][\"hypothesis\"],\n",
    "                \"label\": raw.get(\"labels\")\n",
    "            }\n",
    "            fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 示例调用方式\n",
    "if __name__ == \"__main__\":\n",
    "    input_path =  \"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/repeated/no_error/varierr_peer_no_error_dist.json\"\n",
    "    output_path =\"/Users/phoebeeeee/ongoing/Beyond-noise/dataset/repeated/no_error/varierr_peer_no_error_cleaned.json\"\n",
    "    process_file(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
